\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{huang2007credit}
\citation{poplin2018prediction}
\citation{tollenaar2013method}
\citation{kohavi1996scaling}
\citation{angwin2016machine}
\citation{hardt2016equality}
\citation{kusner2017counterfactual}
\citation{narayanan}
\newlabel{submission}{{1}{1}{}{section.1}{}}
\citation{dwork2012fairness}
\citation{feldman2015certifying}
\citation{kamishima2012fairness}
\citation{zafar2015fairness}
\citation{beutel2017data}
\citation{wadsworth2018achieving}
\citation{zafar2015fairness}
\citation{wadsworth2018achieving}
\citation{kohavi1996scaling}
\citation{zafar2015fairness}
\citation{agarwal2018reductions}
\citation{bobko2004four}
\citation{hu2018short}
\citation{goodfellow2016deep}
\newlabel{q-rule}{{2}{2}{}{equation.2.2}{}}
\citation{zafar2015fairness}
\citation{zafar2015fairness}
\citation{goodfellow2014generative}
\citation{wadsworth2018achieving}
\newlabel{nn-def}{{3}{3}{}{equation.3.3}{}}
\newlabel{bce}{{4}{3}{}{equation.3.4}{}}
\newlabel{method1}{{3.1}{3}{}{subsection.3.1}{}}
\newlabel{decision-boundary-def}{{5}{3}{}{equation.3.5}{}}
\newlabel{penalty-bce}{{8}{3}{}{equation.3.8}{}}
\newlabel{sec:adversarial}{{3.2}{3}{}{subsection.3.2}{}}
\citation{goodfellow2014generative}
\citation{paszke2017pytorch}
\citation{kingma2014adam}
\newlabel{bce}{{9}{4}{}{equation.3.9}{}}
\newlabel{vanilla-net}{{4.1}{4}{}{subsection.4.1}{}}
\newlabel{vanilla-nn}{{1}{5}{For the vanilla neural network, fitted kernel density estimations of test set estimated probabilities that different races (left) and different sexes (right) make over 50K a year. Dotted lines indicate the means of each distribution (Table \ref {vanilla-table})}{figure.1}{}}
\newlabel{vanilla-table}{{1}{5}{For the vanilla neural network, test set mean estimated probabilities of making over 50K for various sensitive groups}{table.1}{}}
\newlabel{boundary-fig-sex}{{2}{5}{Tradeoff between overall neural network accuracy and level of demographic parity for \emph {sex} by varying regularization penalty $\lambda $ on the covariance between the distance to the decision boundary and sensitive attributes. Results are given on the training set (left) and the test set (right)}{figure.2}{}}
\newlabel{boundary-table-sex}{{2}{5}{Numerical results of how accuracy and level of demographic parity change as functions of regularization parameter $\lambda $ for constraining prediction probabilities conditioned on \emph {sex}}{table.2}{}}
\newlabel{boundary-fig-race}{{3}{5}{Tradeoff between overall neural network accuracy and level of demographic parity for \emph {race} by varying regularization penalty $\lambda $ on the covariance between the distance to the decision boundary and sensitive attributes. Results are given on the training set (left) and the test set (right)}{figure.3}{}}
\newlabel{boundary-table-race}{{3}{6}{Numerical results of how accuracy and level of demographic parity change as functions of regularization parameter $\lambda $ for constraining prediction probabilities conditioned on \emph {race}}{table.3}{}}
\newlabel{boundary-bias}{{4}{6}{For the decision boundary-regularized neural network, fitted kernel density estimations of test set estimated probabilities that different races (left) and different sexes (right) make over 50K a year. Dotted lines indicate the means of each distribution}{figure.4}{}}
\newlabel{adv_fig_sex}{{5}{6}{Tradeoff between overall neural network accuracy and level of demographic parity for \emph {sex} by varying weight on adversarial loss $\alpha $. Results are given on the training set (left) and the test set (right)}{figure.5}{}}
\newlabel{adv_fig_race}{{6}{6}{Tradeoff between overall neural network accuracy and level of demographic parity for \emph {race} by varying weight on adversarial loss $\alpha $. Results are given on the training set (left) and the test set (right)}{figure.6}{}}
\newlabel{adv-table}{{4}{6}{Numerical results of how accuracy and level of demographic parity change as functions of regularization parameter $\alpha $ for adversarial models}{table.4}{}}
\bibstyle{icml2019}
\bibdata{example_paper.bib}
\bibcite{agarwal2018reductions}{{1}{2018}{{Agarwal et~al.}}{{Agarwal, Beygelzimer, Dud{\'\i }k, Langford, and Wallach}}}
\bibcite{angwin2016machine}{{2}{2016}{{Angwin et~al.}}{{Angwin, Larson, Mattu, and Kirchner}}}
\bibcite{beutel2017data}{{3}{2017}{{Beutel et~al.}}{{Beutel, Chen, Zhao, and Chi}}}
\bibcite{bobko2004four}{{4}{2004}{{Bobko \& Roth}}{{Bobko and Roth}}}
\bibcite{dwork2012fairness}{{5}{2012}{{Dwork et~al.}}{{Dwork, Hardt, Pitassi, Reingold, and Zemel}}}
\bibcite{feldman2015certifying}{{6}{2015}{{Feldman et~al.}}{{Feldman, Friedler, Moeller, Scheidegger, and Venkatasubramanian}}}
\bibcite{goodfellow2014generative}{{7}{2014}{{Goodfellow et~al.}}{{Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio}}}
\bibcite{goodfellow2016deep}{{8}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, and Courville}}}
\bibcite{hardt2016equality}{{9}{2016}{{Hardt et~al.}}{{Hardt, Price, Srebro, et~al.}}}
\bibcite{hu2018short}{{10}{2018}{{Hu \& Chen}}{{Hu and Chen}}}
\bibcite{huang2007credit}{{11}{2007}{{Huang et~al.}}{{Huang, Chen, and Wang}}}
\bibcite{kamishima2012fairness}{{12}{2012}{{Kamishima et~al.}}{{Kamishima, Akaho, Asoh, and Sakuma}}}
\bibcite{kingma2014adam}{{13}{2014}{{Kingma \& Ba}}{{Kingma and Ba}}}
\bibcite{kohavi1996scaling}{{14}{1996}{{Kohavi}}{{}}}
\bibcite{kusner2017counterfactual}{{15}{2017}{{Kusner et~al.}}{{Kusner, Loftus, Russell, and Silva}}}
\bibcite{narayanan}{{16}{2018}{{Narayanan}}{{}}}
\bibcite{paszke2017pytorch}{{17}{2017}{{Paszke et~al.}}{{Paszke, Gross, Chintala, and Chanan}}}
\newlabel{adv-bias}{{7}{7}{For the adversarial neural network approach, fitted kernel density estimations of test set estimated probabilities that different races (left) and different sexes (right) make over 50K a year. Dotted lines indicate the means of each distribution}{figure.7}{}}
\bibcite{poplin2018prediction}{{18}{2018}{{Poplin et~al.}}{{Poplin, Varadarajan, Blumer, Liu, McConnell, Corrado, Peng, and Webster}}}
\bibcite{tollenaar2013method}{{19}{2013}{{Tollenaar \& Van~der Heijden}}{{Tollenaar and Van~der Heijden}}}
\bibcite{wadsworth2018achieving}{{20}{2018}{{Wadsworth et~al.}}{{Wadsworth, Vera, and Piech}}}
\bibcite{zafar2015fairness}{{21}{2015}{{Zafar et~al.}}{{Zafar, Valera, Rodriguez, and Gummadi}}}
